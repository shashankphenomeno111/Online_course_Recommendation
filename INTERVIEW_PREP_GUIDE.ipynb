{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udf93 Course Recommendation System - Complete Interview Guide\n",
    "\n",
    "**Author:** Your Name  \n",
    "**Date:** January 2026  \n",
    "**Purpose:** Interview Preparation & Project Explanation\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udccb Table of Contents\n",
    "\n",
    "1. [Project Overview & Problem Statement](#1)\n",
    "2. [Dataset Understanding](#2)\n",
    "3. [Exploratory Data Analysis (EDA)](#3)\n",
    "4. [Data Preprocessing](#4)\n",
    "5. [Model Development](#5)\n",
    "6. [Model Evaluation](#6)\n",
    "7. [Deployment](#7)\n",
    "8. [Conclusion & Key Takeaways](#8)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1\ufe0f\u20e3 Project Overview & Problem Statement\n",
    "\n",
    "### \ud83c\udfaf **What Problem Are We Solving?**\n",
    "\n",
    "**The Challenge:**\n",
    "- Online learning platforms have **thousands of courses**\n",
    "- Users feel **overwhelmed** by choices\n",
    "- Users **waste time** searching for relevant courses\n",
    "- Platforms lose revenue when users can't find what they need\n",
    "\n",
    "**Our Solution:**\n",
    "Build an intelligent **Course Recommendation System** that:\n",
    "- Suggests **personalized courses** based on user preferences\n",
    "- Uses **Machine Learning** to learn from user behavior\n",
    "- Provides **multiple recommendation strategies** for different scenarios\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udcca **Project Workflow**\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Raw Data      \u2502\n",
    "\u2502 (100K records)  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "         \u2502\n",
    "         \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502      EDA        \u2502  \u25c4\u2500\u2500 Understand patterns, distributions\n",
    "\u2502  Visualization  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "         \u2502\n",
    "         \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502 Preprocessing   \u2502  \u25c4\u2500\u2500 Clean, encode, transform data\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "         \u2502\n",
    "         \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502 Model Building  \u2502  \u25c4\u2500\u2500 Content-Based, Collaborative, Hybrid\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "         \u2502\n",
    "         \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Evaluation    \u2502  \u25c4\u2500\u2500 RMSE, MAE, Precision, Coverage\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "         \u2502\n",
    "         \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   Deployment    \u2502  \u25c4\u2500\u2500 Streamlit Dashboard\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udfa4 **Interview Talking Points**\n",
    "\n",
    "**When asked \"Tell me about your project\":**\n",
    "\n",
    "> *\"I built a Course Recommendation System that helps learners discover relevant courses from a catalog of 10,000+ courses. The system uses 100,000 user interaction records to provide personalized recommendations using three different approaches: Content-Based filtering for explainability, Collaborative Filtering for accuracy, and a Hybrid approach for production deployment.\"*\n",
    "\n",
    "**Key Points to Mention:**\n",
    "1. \u2705 Solved real-world problem (information overload)\n",
    "2. \u2705 Used 100,000 real user interactions\n",
    "3. \u2705 Implemented 3 different algorithms\n",
    "4. \u2705 Comprehensive evaluation with 5 metrics\n",
    "5. \u2705 Professional deployment with Streamlit\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2\ufe0f\u20e3 Dataset Understanding\n",
    "\n",
    "### \ud83d\udce6 **What Data Do We Have?**\n",
    "\n",
    "**Dataset:** `processed_courses.csv`\n",
    "\n",
    "**Size:** 100,000 user-course interaction records\n",
    "\n",
    "**Features (14 columns):**\n",
    "\n",
    "| Column Name | Type | Description | Example |\n",
    "|------------|------|-------------|----------|\n",
    "| **user_id** | int | Unique user identifier | 15796 |\n",
    "| **course_id** | int | Unique course identifier | 9366 |\n",
    "| **course_name** | str | Name of the course | \"Python for Beginners\" |\n",
    "| **instructor** | str | Course instructor | \"Emma Harris\" |\n",
    "| **rating** | float | User rating (1-5) | 4.5 |\n",
    "| **difficulty_level** | str | Beginner/Intermediate/Advanced | \"Beginner\" |\n",
    "| **course_price** | float | Price in USD | 39.99 |\n",
    "| **enrollment_numbers** | int | Total enrollments | 48,245 |\n",
    "| **previous_courses_taken** | int | User's course history | 12 |\n",
    "| **time_spent_hours** | float | Time spent on course | 25.5 |\n",
    "| **completion_status** | int | 0 or 1 | 1 |\n",
    "| **age** | int | User age | 28 |\n",
    "| **gender** | str | Male/Female | \"Male\" |\n",
    "| **education_level** | str | Education background | \"Bachelor's\" |\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udd0d **Why This Data is Important**\n",
    "\n",
    "**For Content-Based Filtering:**\n",
    "- `course_name`, `instructor`, `difficulty_level` \u2192 Course features\n",
    "- We can find **similar courses** based on these attributes\n",
    "\n",
    "**For Collaborative Filtering:**\n",
    "- `user_id`, `course_id`, `rating` \u2192 User-item matrix\n",
    "- We can find **similar users** who liked similar courses\n",
    "\n",
    "**For Analysis:**\n",
    "- `enrollment_numbers`, `price`, `time_spent` \u2192 Business insights\n",
    "- Understand what makes courses popular\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udfa4 **Interview Talking Points**\n",
    "\n",
    "**When asked \"Tell me about your dataset\":**\n",
    "\n",
    "> *\"I worked with 100,000 user-course interaction records containing 14 features including user demographics, course attributes, and engagement metrics like ratings and time spent. The dataset spans 10,000+ unique courses and thousands of users, providing rich information for both content-based and collaborative filtering approaches.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('processed_courses.csv')\n",
    "\n",
    "print(\"\u2705 Dataset loaded successfully!\")\n",
    "print(f\"\ud83d\udcca Shape: {df.shape[0]:,} rows \u00d7 {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the data\n",
    "print(\"\\n\ud83d\udccb First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and memory usage\n",
    "print(\"\\n\ud83d\udd0d Dataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"\\n\ud83d\udcc8 Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\n\u2753 Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0])\n",
    "\n",
    "if missing.sum() == 0:\n",
    "    print(\"\u2705 No missing values found! Dataset is clean.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key statistics\n",
    "print(\"\\n\ud83d\udcca Key Statistics:\")\n",
    "print(f\"Total Courses: {df['course_id'].nunique():,}\")\n",
    "print(f\"Total Users: {df['user_id'].nunique():,}\")\n",
    "print(f\"Total Interactions: {len(df):,}\")\n",
    "print(f\"Average Rating: {df['rating'].mean():.2f}/5.0\")\n",
    "print(f\"Average Price: ${df['course_price'].mean():.2f}\")\n",
    "print(f\"Average Enrollment: {df['enrollment_numbers'].mean():,.0f} students/course\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udca1 **What We Learned from Basic Exploration**\n",
    "\n",
    "1. **Clean Data** - No missing values, ready for analysis\n",
    "2. **Large Scale** - 100K interactions provide robust training data\n",
    "3. **Diverse Courses** - 10,000+ courses across multiple categories\n",
    "4. **Good Engagement** - Average rating of ~3.5-4.0 shows active users\n",
    "5. **Varied Pricing** - Wide range of course prices (free to premium)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3\ufe0f\u20e3 Exploratory Data Analysis (EDA)\n",
    "\n",
    "### \ud83c\udfaf **Why Do We Do EDA?**\n",
    "\n",
    "EDA helps us:\n",
    "1. **Understand data distributions** - Are ratings normally distributed?\n",
    "2. **Find patterns** - Which courses are most popular?\n",
    "3. **Identify relationships** - Does price affect ratings?\n",
    "4. **Make decisions** - Which features to use for modeling?\n",
    "5. **Spot anomalies** - Any unusual data points?\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udcca **Visualization 1: Rating Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating Distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['rating'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Rating', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Course Ratings', fontsize=14, fontweight='bold')\n",
    "plt.axvline(df['rating'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"rating\"].mean():.2f}')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df['rating'].plot(kind='box', vert=False, color='lightblue')\n",
    "plt.xlabel('Rating', fontsize=12)\n",
    "plt.title('Box Plot of Ratings', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Rating Statistics:\")\n",
    "print(f\"Mean: {df['rating'].mean():.2f}\")\n",
    "print(f\"Median: {df['rating'].median():.2f}\")\n",
    "print(f\"Std Dev: {df['rating'].std():.2f}\")\n",
    "print(f\"Min: {df['rating'].min():.2f}\")\n",
    "print(f\"Max: {df['rating'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \ud83d\udd0d **What This Graph Tells Us:**\n",
    "\n",
    "**Histogram (Left):**\n",
    "- Shows how ratings are distributed across all interactions\n",
    "- **Peak around 3.5-4.0** \u2192 Most users are satisfied but not ecstatic\n",
    "- **Red line** \u2192 Average rating (mean)\n",
    "- **Shape** \u2192 If bell-shaped (normal), ratings are balanced\n",
    "\n",
    "**Box Plot (Right):**\n",
    "- Shows the spread and outliers\n",
    "- **Box** \u2192 50% of data falls here (interquartile range)\n",
    "- **Line inside box** \u2192 Median rating\n",
    "- **Dots outside** \u2192 Outliers (extremely low/high ratings)\n",
    "\n",
    "**Interview Point:**\n",
    "> *\"The rating distribution shows that most users rate courses between 3-4 stars, with a mean of around 3.5. This indicates general satisfaction with course quality. The box plot shows few outliers, suggesting consistent rating behavior.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udcca **Visualization 2: Course Difficulty Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difficulty Level Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "difficulty_counts = df['difficulty_level'].value_counts()\n",
    "colors = ['#667eea', '#764ba2', '#f093fb']\n",
    "\n",
    "plt.pie(difficulty_counts.values, labels=difficulty_counts.index, autopct='%1.1f%%',\n",
    "        colors=colors, startangle=90, textprops={'fontsize': 12})\n",
    "plt.title('Course Distribution by Difficulty Level', fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Difficulty Distribution:\")\n",
    "for level, count in difficulty_counts.items():\n",
    "    print(f\"{level}: {count:,} courses ({count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \ud83d\udd0d **What This Graph Tells Us:**\n",
    "\n",
    "**Pie Chart:**\n",
    "- Shows the proportion of courses at each difficulty level\n",
    "- **Why it matters:** Helps us understand course catalog balance\n",
    "- **For modeling:** We might weight recommendations differently based on user's skill level\n",
    "\n",
    "**Typical Observations:**\n",
    "- Usually **Beginner > Intermediate > Advanced**\n",
    "- More beginner courses attract new learners\n",
    "- Fewer advanced courses = specialized content\n",
    "\n",
    "**Interview Point:**\n",
    "> *\"The platform has a good distribution across difficulty levels, with more beginner-friendly content to onboard new users, and specialized advanced courses for experienced learners.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udcca **Visualization 3: Price vs Rating Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price vs Rating Scatter Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.scatter(df['course_price'], df['rating'], alpha=0.3, s=30, c='#667eea')\n",
    "plt.xlabel('Course Price ($)', fontsize=12)\n",
    "plt.ylabel('Rating (1-5)', fontsize=12)\n",
    "plt.title('Course Price vs Rating', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = df['course_price'].corr(df['rating'])\n",
    "plt.text(0.7, 0.95, f'Correlation: {correlation:.3f}', \n",
    "         transform=plt.gca().transAxes, fontsize=12, \n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Price-Rating Correlation: {correlation:.3f}\")\n",
    "if abs(correlation) < 0.3:\n",
    "    print(\"   \u2192 Weak correlation: Price doesn't strongly affect ratings\")\n",
    "elif abs(correlation) < 0.7:\n",
    "    print(\"   \u2192 Moderate correlation\")\n",
    "else:\n",
    "    print(\"   \u2192 Strong correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  \ud83d\udd0d **What This Graph Tells Us:**\n",
    "\n",
    "**Scatter Plot Analysis:**\n",
    "- Each dot = one course\n",
    "- **X-axis:** Price in dollars\n",
    "- **Y-axis:** User rating\n",
    "\n",
    "**Correlation Value:**\n",
    "- **Close to 0:** No relationship (price doesn't affect rating)\n",
    "- **Positive:** Higher price \u2192 Higher rating\n",
    "- **Negative:** Higher price \u2192 Lower rating\n",
    "\n",
    "**Why This Matters:**\n",
    "- If correlation is weak \u2192 **Quality isn't tied to price**\n",
    "- Good for users \u2192 Can find great courses at any price point\n",
    "- For recommendations \u2192 Don't need to bias toward expensive courses\n",
    "\n",
    "**Interview Point:**\n",
    "> *\"I analyzed the relationship between price and ratings and found weak correlation, indicating that course quality isn't necessarily tied to price. This validates our decision to recommend based on content similarity and user preferences rather than price.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udcca **Visualization 4: Top Instructors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Instructors by Course Count\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "top_instructors = df['instructor'].value_counts().head(10)\n",
    "\n",
    "plt.barh(range(len(top_instructors)), top_instructors.values, color='#764ba2')\n",
    "plt.yticks(range(len(top_instructors)), top_instructors.index)\n",
    "plt.xlabel('Number of Course Interactions', fontsize=12)\n",
    "plt.ylabel('Instructor', fontsize=12)\n",
    "plt.title('Top 10 Most Active Instructors', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate(top_instructors.values):\n",
    "    plt.text(v + 50, i, f'{v:,}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Top Instructors:\")\n",
    "for idx, (instructor, count) in enumerate(top_instructors.items(), 1):\n",
    "    print(f\"{idx}. {instructor}: {count:,} interactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \ud83d\udd0d **What This Graph Tells Us:**\n",
    "\n",
    "**Bar Chart (Horizontal):**\n",
    "- Shows which instructors have the most user interactions\n",
    "- **Longer bar** = More popular instructor\n",
    "\n",
    "**Why This Matters:**\n",
    "- Popular instructors = quality content\n",
    "- Can use instructor as a feature for content-based filtering\n",
    "- Users who like one course from an instructor might like others\n",
    "\n",
    "**For Recommendations:**\n",
    "- Include instructor in TF-IDF features\n",
    "- \"Users who liked this instructor also liked...\"\n",
    "- Can create instructor-specific recommendations\n",
    "\n",
    "**Interview Point:**\n",
    "> *\"I identified the top instructors and incorporated instructor names into the content-based filtering features. This allows the system to recommend other courses from instructors a user has previously enjoyed.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udcca **Visualization 5: Correlation Heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap for Numerical Features\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Select numerical columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdPu', \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap of Numerical Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Strong Correlations (|r| > 0.5):\")\n",
    "for i in range(len(corr_matrix)):\n",
    "    for j in range(i+1, len(corr_matrix)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.5:\n",
    "            print(f\"{corr_matrix.index[i]} \u2194 {corr_matrix.columns[j]}: {corr_matrix.iloc[i, j]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \ud83d\udd0d **What This Graph Tells Us:**\n",
    "\n",
    "**Heatmap Reading:**\n",
    "- **Color intensity** = Strength of correlation\n",
    "- **Dark purple** = Strong positive correlation (+1)\n",
    "- **Light pink** = Weak correlation (0)\n",
    "- **Numbers** = Exact correlation values\n",
    "\n",
    "**What to Look For:**\n",
    "1. **Diagonal = 1.0** (feature correlated with itself - perfect!)\n",
    "2. **High values off-diagonal** = Features move together\n",
    "3. **Low values** = Independent features (good for modeling)\n",
    "\n",
    "**Common Patterns:**\n",
    "- `time_spent_hours` \u2194 `completion_status` \u2192 More time = More completions\n",
    "- `rating` \u2194 `enrollment_numbers` \u2192 Popular courses rated more\n",
    "\n",
    "**For Feature Engineering:**\n",
    "- Highly correlated features \u2192 Might remove one (redundant)\n",
    "- Independent features \u2192 Keep all (each adds unique information)\n",
    "\n",
    "**Interview Point:**\n",
    "> *\"The correlation analysis revealed that time spent and completion status are strongly related, which makes sense. However, most features show low correlation, meaning each provides unique information for the recommendation models.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83c\udfaf **Key Insights from EDA**\n",
    "\n",
    "| Insight | Finding | Implication for Modeling |\n",
    "|---------|---------|-------------------------|\n",
    "| **Ratings** | Most ratings are 3-4 stars | Need good differentiation in collaborative filtering |\n",
    "| **Difficulty** | Balanced across levels | Can recommend based on user's skill level |\n",
    "| **Price** | Weak correlation with rating | Don't bias recommendations by price |\n",
    "| **Instructors** | Some very popular | Use instructor as a content feature |\n",
    "| **Features** | Mostly independent | Keep all features for rich representations |\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udfa4 **EDA Summary for Interview**\n",
    "\n",
    "> *\"I performed comprehensive exploratory analysis including distribution plots, correlation analysis, and feature relationships. Key findings were: ratings cluster around 3.5 stars showing consistent quality, difficulty levels are well-balanced, and price doesn't correlate with ratings. I identified top instructors who could be leveraged for content-based filtering. The correlation heatmap showed features are mostly independent, meaning each provides unique signal for the models.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4\ufe0f\u20e3 Data Preprocessing\n",
    "\n",
    "### \ud83c\udfaf **Why Preprocess Data?**\n",
    "\n",
    "Machine Learning models need data in specific formats:\n",
    "- **Text \u2192 Numbers** (algorithms work with numbers)\n",
    "- **Consistent scales** (some algorithms sensitive to scale)\n",
    "- **Clean format** (no missing values, proper types)\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83d\udd04 **Our Preprocessing Pipeline**\n",
    "\n",
    "```\n",
    "Raw Data\n",
    "   \u2193\n",
    "1. Label Encoding (difficulty_level, gender, education)\n",
    "   \u2193\n",
    "2. Feature Engineering (combine course features)\n",
    "   \u2193\n",
    "3. TF-IDF Vectorization (text to numbers)\n",
    "   \u2193\n",
    "4. User-Item Matrix Creation\n",
    "   \u2193\n",
    "Ready for Modeling!\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd **Step 1: Label Encoding**\n",
    "\n",
    "**What:** Convert categorical text to numbers\n",
    "\n",
    "**Why:** Algorithms can only work with numerical data\n",
    "\n",
    "**How:** Assign each unique value a number\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Difficulty:     Label:\n",
    "Beginner    \u2192   0\n",
    "Intermediate \u2192  1  \n",
    "Advanced    \u2192   2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create label encoder\n",
    "le_difficulty = LabelEncoder()\n",
    "le_gender = LabelEncoder()\n",
    "le_education = LabelEncoder()\n",
    "\n",
    "# Encode categorical variables\n",
    "df['difficulty_encoded'] = le_difficulty.fit_transform(df['difficulty_level'])\n",
    "df['gender_encoded'] = le_gender.fit_transform(df['gender'])\n",
    "df['education_encoded'] = le_education.fit_transform(df['education_level'])\n",
    "\n",
    "print(\"\u2705 Label Encoding Complete!\")\n",
    "print(\"\\n\ud83d\udcca Difficulty Mapping:\")\n",
    "for i, label in enumerate(le_difficulty.classes_):\n",
    "    print(f\"   {label} \u2192 {i}\")\n",
    "\n",
    "print(\"\\n\ud83d\udcca Sample of encoded data:\")\n",
    "df[['difficulty_level', 'difficulty_encoded', 'gender', 'gender_encoded']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \ud83c\udfa4 **Interview Talking Point:**\n",
    "\n",
    "> *\"I used Label Encoding to convert categorical variables like difficulty level, gender, and education into numerical format. This allows the algorithms to process these features mathematically while preserving the unique categories.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd **Step 2: Feature Engineering for Content-Based**\n",
    "\n",
    "**Goal:** Combine course features into one text field\n",
    "\n",
    "**Why:** TF-IDF works on text, so we combine:\n",
    "- Course name\n",
    "- Instructor name  \n",
    "- Difficulty level\n",
    "\n",
    "**Result:** Rich text representation of each course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique courses dataframe\n",
    "df_unique = df.drop_duplicates(subset='course_id')\n",
    "\n",
    "# Combine features into single text field\n",
    "df_unique['combined_features'] = (\n",
    "    df_unique['course_name'] + ' ' + \n",
    "    df_unique['instructor'] + ' ' + \n",
    "    df_unique['difficulty_level']\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Created {len(df_unique):,} unique course profiles\")\n",
    "print(\"\\n\ud83d\udcdd Sample combined features:\")\n",
    "print(df_unique[['course_name', 'combined_features']].head(3).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \ud83d\udd0d **Example:**\n",
    "\n",
    "**Original:**\n",
    "- Course: \"Python for Beginners\"\n",
    "- Instructor: \"Emma Harris\"\n",
    "- Difficulty: \"Beginner\"\n",
    "\n",
    "**Combined:**\n",
    "- \"Python for Beginners Emma Harris Beginner\"\n",
    "\n",
    "**Why This Works:**\n",
    "- Courses with similar **names** will be similar\n",
    "- Courses from same **instructor** will be similar  \n",
    "- Courses at same **difficulty** will be similar\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd **Step 3: TF-IDF Vectorization**\n",
    "\n",
    "**TF-IDF** = Term Frequency - Inverse Document Frequency\n",
    "\n",
    "**What it does:**\n",
    "- Converts text to numerical vectors\n",
    "- Gives weight to important words\n",
    "- Reduces weight of common words\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "\"Python for Beginners\" \u2192 [0.5, 0.8, 0, 0.6, 0, ...]\n",
    "\"Java for Beginners\"   \u2192 [0, 0.8, 0.5, 0.6, 0, ...]\n",
    "```\n",
    "\n",
    "**Why:**\n",
    "- Word \"Beginners\" appears in both \u2192 Lower weight (common)\n",
    "- Words \"Python\", \"Java\" \u2192 Higher weight (distinctive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform\n",
    "tfidf_matrix = tfidf.fit_transform(df_unique['combined_features'])\n",
    "\n",
    "print(\"\u2705 TF-IDF Vectorization Complete!\")\n",
    "print(f\"\\n\ud83d\udcca Matrix Shape: {tfidf_matrix.shape}\")\n",
    "print(f\"   \u2192 {tfidf_matrix.shape[0]:,} courses\")\n",
    "print(f\"   \u2192 {tfidf_matrix.shape[1]:,} unique words (features)\")\n",
    "print(f\"   \u2192 Sparsity: {(1 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\n\ud83d\udcdd Sample vocabulary:\")\n",
    "print(list(tfidf.vocabulary_.keys())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \ud83c\udfa4 **Interview Talking Point:**\n",
    "\n",
    "> *\"I used TF-IDF vectorization to convert course text features into numerical vectors. This created a sparse matrix of about X thousand features, where each course is represented by the importance-weighted words in its title, instructor name, and difficulty level. The high sparsity (~99%) is normal for text data and efficiently handled by sparse matrix representations.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udcdd **Step 4: Cosine Similarity Matrix**\n",
    "\n",
    "**Purpose:** Measure how similar courses are to each other\n",
    "\n",
    "**Cosine Similarity:**\n",
    "- Measures angle between vectors\n",
    "- Range: 0 (completely different) to 1 (identical)\n",
    "- Works well for text data\n",
    "\n",
    "**Visual:**\n",
    "```\n",
    "Course A: \u2192\n",
    "Course B: \u2197  (Small angle = Similar = High score)\n",
    "Course C: \u2193  (Large angle = Different = Low score)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "print(\"\u2705 Cosine Similarity Matrix Created!\")\n",
    "print(f\"\\n\ud83d\udcca Matrix Shape: {cosine_sim.shape} (square matrix)\")\n",
    "print(f\"   Each cell = similarity between two courses\")\n",
    "\n",
    "# Show sample similarities\n",
    "print(\"\\n\ud83d\udcdd Sample: First course's similarities:\")\n",
    "print(f\"   With itself: {cosine_sim[0, 0]:.3f} (should be 1.0)\")\n",
    "print(f\"   With course 2: {cosine_sim[0, 1]:.3f}\")\n",
    "print(f\"   With course 3: {cosine_sim[0, 2]:.3f}\")\n",
    "\n",
    "# Find most similar course to the first one\n",
    "similar_indices = cosine_sim[0].argsort()[::-1][1:6]  # Top 5, excluding itself\n",
    "print(\"\\n\ud83c\udfaf Top 5 most similar courses to:\", df_unique['course_name'].iloc[0])\n",
    "for idx in similar_indices:\n",
    "    print(f\"   {df_unique['course_name'].iloc[idx]} (similarity: {cosine_sim[0, idx]:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}